{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Face Emotion Recognition Model Creation </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are doing analysis on a largely popular dataset fer2013 which has test and train csv files<br> consisting of numpy arrays for the images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>Before we begin with the code, pasting below a sample code to convert the image into numpy array and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert image to numpy array and store in csv\n",
    "\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import sys\n",
    "# import os\n",
    "# import csv\n",
    "\n",
    "# # default format can be changed as needed\n",
    "# def createFileList(myDir, format='.jpg'):\n",
    "#     fileList = []\n",
    "#     print(myDir)\n",
    "#     for root, dirs, files in os.walk(myDir, topdown=False):\n",
    "#         for name in files:\n",
    "#             if name.endswith(format):\n",
    "#                 fullName = os.path.join(root, name)\n",
    "#                 fileList.append(fullName)\n",
    "#     return fileList\n",
    "\n",
    "# load the original image\n",
    "# myFileList = createFileList('/path_to_directory_with_images/')\n",
    "\n",
    "# for file in myFileList:\n",
    "#     print(file)\n",
    "#     img_file = Image.open(file)\n",
    "#     # img_file.show()\n",
    "\n",
    "#     # get original image parameters...\n",
    "#     width, height = img_file.size\n",
    "#     format = img_file.format\n",
    "#     mode = img_file.mode\n",
    "\n",
    "#     # Make image Greyscale\n",
    "#     img_grey = img_file.convert('L')\n",
    "#     #img_grey.save('result.png')\n",
    "#     #img_grey.show()\n",
    "\n",
    "#     # Save Greyscale values\n",
    "#     value = np.asarray(img_grey.getdata(), dtype=np.int).reshape((img_grey.size[1], img_grey.size[0]))\n",
    "#     value = value.flatten()\n",
    "#     print(value)\n",
    "#     with open(\"name_you_want.csv\", 'a') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert csv to image\n",
    "\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# os.makedirs(\"output\")\n",
    "\n",
    "# with open(\"train.csv\") as f:\n",
    "#     content = f.readlines()\n",
    "\n",
    "# lines = np.array(content)\n",
    "\n",
    "# num_of_instances = lines.size\n",
    "\n",
    "# for i in range(1,num_of_instances):\n",
    "#     try:\n",
    "#         emotion, img = lines[i].split(\",\")\n",
    "#         img = img.replace('\"', '')\n",
    "#         img = img.replace('\\n', '')\n",
    "#         pixels = img.split(\" \")\n",
    "\n",
    "#         pixels = np.array(pixels, 'float32')\n",
    "#         image = pixels.reshape(48, 48)\n",
    "\n",
    "#         path_file_name = f\"output/{i}_{emotion}.jpg\"\n",
    "#         cv2.imwrite(path_file_name, image)\n",
    "\n",
    "#     except Exception as ex:\n",
    "#         print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We will set up some functions for as utilities for building the model later </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "               use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "               use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "               # kernel_regularizer=regularization,\n",
    "               padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax', name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager(object):\n",
    "    \"\"\"Class for loading fer2013 emotion classification dataset or\n",
    "        imdb gender classification dataset.\"\"\"\n",
    "    def __init__(self, dataset_name='imdb',\n",
    "                 dataset_path=None, image_size=(48, 48)):\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_size = image_size\n",
    "        if self.dataset_path is not None:\n",
    "            self.dataset_path = dataset_path\n",
    "        elif self.dataset_name == 'fer2013':\n",
    "            self.dataset_path = './fer2013.csv'\n",
    "        else:\n",
    "            raise Exception(\n",
    "                    'Incorrect dataset name, please input imdb or fer2013')\n",
    "\n",
    "    def get_data(self):\n",
    "        if self.dataset_name == 'fer2013':\n",
    "            ground_truth_data = self._load_fer2013()\n",
    "        \n",
    "        return ground_truth_data\n",
    "\n",
    "    def _load_fer2013(self):\n",
    "        data = pd.read_csv(self.dataset_path)\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'), self.image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "        emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "        return faces, emotions\n",
    "\n",
    "def get_labels(dataset_name):\n",
    "    if dataset_name == 'fer2013':\n",
    "        return {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy',\n",
    "                4: 'sad', 5: 'surprise', 6: 'neutral'}\n",
    "    else:\n",
    "        raise Exception('Invalid dataset name')\n",
    "\n",
    "\n",
    "def get_class_to_arg(dataset_name='fer2013'):\n",
    "    if dataset_name == 'fer2013':\n",
    "        return {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'sad': 4,\n",
    "                'surprise': 5, 'neutral': 6}\n",
    "\n",
    "    else:\n",
    "        raise Exception('Invalid dataset name')\n",
    "\n",
    "def split_data(x, y, validation_split=.2):\n",
    "    num_samples = len(x)\n",
    "    num_train_samples = int((1 - validation_split)*num_samples)\n",
    "    train_x = x[:num_train_samples]\n",
    "    train_y = y[:num_train_samples]\n",
    "    val_x = x[num_train_samples:]\n",
    "    val_y = y[num_train_samples:]\n",
    "    train_data = (train_x, train_y)\n",
    "    val_data = (val_x, val_y)\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model Training ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><b>Model Architecture</b> <br> <img src=\"image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Experiment with the Epochs, 10000 epochs give a accuracy of around 70%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "input_shape = (64, 64, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = './emotion_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 62, 62, 8)    72          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 62, 62, 8)    32          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 62, 62, 8)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 60, 60, 8)    576         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 60, 60, 8)    32          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 60, 60, 8)    0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_9 (SeparableCo (None, 60, 60, 16)   200         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 60, 60, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_10 (SeparableC (None, 60, 60, 16)   400         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 60, 60, 16)   64          separable_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 30, 30, 16)   128         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 30, 30, 16)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 30, 30, 16)   64          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 30, 30, 16)   0           max_pooling2d_5[0][0]            \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_11 (SeparableC (None, 30, 30, 32)   656         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 30, 30, 32)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_12 (SeparableC (None, 30, 30, 32)   1312        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 30, 30, 32)   128         separable_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 15, 15, 32)   512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 15, 15, 32)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 15, 15, 32)   128         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 15, 15, 32)   0           max_pooling2d_6[0][0]            \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_13 (SeparableC (None, 15, 15, 64)   2336        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 15, 15, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_14 (SeparableC (None, 15, 15, 64)   4672        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 15, 15, 64)   256         separable_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 64)     2048        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 64)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 64)     256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 64)     0           max_pooling2d_7[0][0]            \n",
      "                                                                 batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_15 (SeparableC (None, 8, 8, 128)    8768        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_16 (SeparableC (None, 8, 8, 128)    17536       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 4, 4, 128)    8192        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 4, 4, 128)    512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 4, 4, 128)    0           max_pooling2d_8[0][0]            \n",
      "                                                                 batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 7)      8071        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 7)            0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: fer2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shreyash\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:36: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "898/897 [==============================] - 316s 352ms/step - loss: 1.7477 - accuracy: 0.3403 - val_loss: 1.5909 - val_accuracy: 0.4153\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.59086, saving model to ./emotion_modelsfer2013_mini_XCEPTION.01-0.42.hdf5\n",
      "Epoch 2/5\n",
      "898/897 [==============================] - 326s 363ms/step - loss: 1.4725 - accuracy: 0.4485 - val_loss: 1.4832 - val_accuracy: 0.4572\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.59086 to 1.48320, saving model to ./emotion_modelsfer2013_mini_XCEPTION.02-0.46.hdf5\n",
      "Epoch 3/5\n",
      "898/897 [==============================] - 334s 371ms/step - loss: 1.3621 - accuracy: 0.4906 - val_loss: 1.4286 - val_accuracy: 0.4664\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.48320 to 1.42858, saving model to ./emotion_modelsfer2013_mini_XCEPTION.03-0.47.hdf5\n",
      "Epoch 4/5\n",
      "898/897 [==============================] - 316s 351ms/step - loss: 1.3004 - accuracy: 0.5147 - val_loss: 1.3120 - val_accuracy: 0.5145\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.42858 to 1.31197, saving model to ./emotion_modelsfer2013_mini_XCEPTION.04-0.51.hdf5\n",
      "Epoch 5/5\n",
      "898/897 [==============================] - 363s 404ms/step - loss: 1.2579 - accuracy: 0.5294 - val_loss: 1.3788 - val_accuracy: 0.5077\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.31197\n"
     ]
    }
   ],
   "source": [
    "datasets = ['fer2013']\n",
    "for dataset_name in datasets:\n",
    "    print('Training dataset:', dataset_name)\n",
    "\n",
    "    # callbacks\n",
    "    log_file_path = base_path + dataset_name + '_emotion_training.log'\n",
    "    csv_logger = CSVLogger(log_file_path, append=False)\n",
    "    early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "    reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "    trained_models_path = base_path + dataset_name + '_mini_XCEPTION'\n",
    "    model_names = trained_models_path + '.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "    callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "    # loading dataset\n",
    "    data_loader = DataManager(dataset_name, image_size=input_shape[:2])\n",
    "    faces, emotions = data_loader.get_data()\n",
    "    faces = preprocess_input(faces)\n",
    "    num_samples, num_classes = emotions.shape\n",
    "    train_data, val_data = split_data(faces, emotions, validation_split)\n",
    "    train_faces, train_emotions = train_data\n",
    "    model.fit_generator(data_generator.flow(train_faces, train_emotions,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(train_faces) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> The model is trained for just 5 epochs as example. Training it with batch size of 32 and 10000 epochs will give an accuracy of around 70-72%<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
